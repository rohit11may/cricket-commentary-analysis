{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import string\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "from random import randint, shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk import ngrams\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "pd.set_option('max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data!\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename):\n",
    "    with open(f\"{filename}.json\", \"rb\") as f:\n",
    "        data = json.load(f)\n",
    "    print(\"Loaded data!\")\n",
    "    return data\n",
    "        \n",
    "def load_df(filename):\n",
    "    with open(f\"{filename}.pkl\", \"rb\") as f:\n",
    "        d = pickle.load(f)\n",
    "    return d\n",
    "        \n",
    "def save_data(data, filename):\n",
    "    with open(f\"{filename}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "        \n",
    "def export_to_json(data):\n",
    "    with open('matches.json', 'w') as json_file:\n",
    "        json.dump(data, json_file)\n",
    "    \n",
    "i1b = lambda m : m['commentary']['innings1']['balls']\n",
    "i2b = lambda m : m['commentary']['innings2']['balls']\n",
    "i1o = lambda m : m['commentary']['innings1']['over_summaries']\n",
    "i2o = lambda m : m['commentary']['innings2']['over_summaries']\n",
    "df, players = load_df(\"dale_df\"), load_data('player_table')\n",
    "\n",
    "all_names = set()\n",
    "ambigNames = set(['short', 'ball', 'head', 'little', 'chase', 'cutting', 'cross'])\n",
    "for profile in players.values():\n",
    "    name = profile['known_as'].split(' ')\n",
    "    ambig = any(n.lower() in ambigNames for n in name)\n",
    "    if not ambig:\n",
    "        all_names.update(name)\n",
    "        all_names.update([n.lower() for n in name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_</th>\n",
       "      <th>hand_</th>\n",
       "      <th>length_</th>\n",
       "      <th>line_</th>\n",
       "      <th>outcome_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steyn to Jaques, full and on the legs, swinging in, Jaques lets it go past, no runs, fielded by Boucher</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steyn to Jaques, good length but down leg, Jaques drives, no runs, fielded by Botha</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steyn to Jaques, short of a length outside the off stump, Jaques plays no shot, no runs, fielded by Boucher</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(no ball) Steyn to Jaques, good length delivery just outside the off stump, Jaques lets it go past, no runs, fielded by Boucher</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Steyn to Jaques, fuller length outside the off stump , Jaques drives in air over cover fielder, 4 runs</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                              desc_  \\\n",
       "0   Steyn to Jaques, full and on the legs, swinging in, Jaques lets it go past, no runs, fielded by Boucher                           \n",
       "1   Steyn to Jaques, good length but down leg, Jaques drives, no runs, fielded by Botha                                               \n",
       "2   Steyn to Jaques, short of a length outside the off stump, Jaques plays no shot, no runs, fielded by Boucher                       \n",
       "3   (no ball) Steyn to Jaques, good length delivery just outside the off stump, Jaques lets it go past, no runs, fielded by Boucher   \n",
       "4   Steyn to Jaques, fuller length outside the off stump , Jaques drives in air over cover fielder, 4 runs                            \n",
       "\n",
       "   hand_  length_  line_  outcome_  \n",
       "0  1      2        2      0         \n",
       "1  1      3        3      0         \n",
       "2  1      4        1      0         \n",
       "3  1      3        1      4         \n",
       "4  1      2        1      12        "
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords as st\n",
    "exceptions = ['a', 'off', 'against', 'between', 'into', 'through', 'above', 'below', 'up', 'down', 'out', 'in', 'over', 'further', 'of', 'on']\n",
    "stopwords = set(st.words('english'))\n",
    "for w in exceptions:\n",
    "    stopwords.remove(w) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x144cbd160>"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFMBJREFUeJzt3W+MXfV95/H3d6EhwGhtCO0sta0db2Olonb/wIilYreaCd3WQBR4EGWJUGO3VKOqtE1bVsRsHqT7IJKjNk2JdkvlBYqzRQwpocULSVvqMosirWntJGUIhMYlDnhkIFHA7ZCoqbfffXAP5MaMfe+cc+/cc39+vyTL95zzO+f8vnNmPnPmd885NzITSVK5/tWoOyBJGi6DXpIKZ9BLUuEMekkqnEEvSYUz6CWpcAa9JBXOoJekwhn0klS4s0fdAYCLLroop6amaq372muvcf755w+2QyNQQh3W0A7W0A5rUcOhQ4e+kZnf36tdK4J+amqKgwcP1lp3YWGBmZmZwXZoBEqowxrawRraYS1qiIiv9dPOoRtJKpxBL0mFM+glqXAGvSQVzqCXpMIZ9JJUOINekgpn0EtS4Qx6SSpcK+6MHWdTux554/WR3deOsCeStDLP6CWpcAa9JBWuZ9BHxN0R8XJEPLXCslsiIiPiomo6IuITEXE4Ip6MiEuH0WlJUv/6OaO/B9h+8syI2AT8DPB81+yrgS3VvzngjuZdlCQ10TPoM/Nx4JsrLPo4cCuQXfOuAz6ZHQeA9RFx8UB6KkmqpdYYfURcByxl5t+etGgD8ELX9NFqniRpRCIzezeKmAIezsytEXEe8BjwM5l5PCKOANOZ+Y2IeBjYnZmfq9bbD3wwM9/0qSIRMUdneIfJycnL5ufnaxWwvLzMxMRErXUHYXHp+Buvt21YV3s7o65jEKyhHayhHdaihtnZ2UOZOd2rXZ3r6H8I2Az8bUQAbAQ+HxGXA0vApq62G6t5b5KZe4A9ANPT01n3k1hG/Uk0O7uvo7+xfj9GXccgWEM7WEM7tKmGVQ/dZOZiZv5AZk5l5hSd4ZlLM/NFYB/w/urqmyuA45l5bLBdliStRj+XV94H/F/gHRFxNCJuOk3zzwDPAYeB/wn88kB6KUmqrefQTWa+r8fyqa7XCdzcvFuSpEHxzlhJKpxBL0mFM+glqXAG/QBN7Xrkex5bLEltYNBLUuEMekkqnEEvSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVzqCXpMIZ9JJUuJ6fGavv8lnzksZRzzP6iLg7Il6OiKe65v12RHw5Ip6MiD+JiPVdy26LiMMR8WxE/OywOi5J6k8/Qzf3ANtPmvcosDUzfxT4O+A2gIi4BLgB+JFqnd+PiLMG1ltJ0qr1DPrMfBz45knz/iIzT1STB4CN1evrgPnM/KfM/CpwGLh8gP2VJK1SZGbvRhFTwMOZuXWFZf8buD8z/ygi/jtwIDP/qFp2F/DZzHxghfXmgDmAycnJy+bn52sVsLy8zMTERK11V2tx6Xhf7bZtWLfqba9lHcNiDe1gDe2wFjXMzs4eyszpXu0avRkbER8CTgD3rnbdzNwD7AGYnp7OmZmZWn1YWFig7rqrtbPPN2OP3Diz6m2vZR3DYg3tYA3t0KYaagd9ROwE3gVcld/9s2AJ2NTVbGM1T5I0IrWuo4+I7cCtwLsz81tdi/YBN0TEORGxGdgC/HXzbkqS6up5Rh8R9wEzwEURcRT4MJ2rbM4BHo0I6IzL/1JmfikiPgU8TWdI5+bM/H/D6rwkqbeeQZ+Z71th9l2naf8R4CNNOiVJGhwfgSBJhTPoJalwBr0kFc6gl6TCGfRDNrXrEZ96KWmkDHpJKpxBL0mFM+glqXAGvSQVzo8SHIKV3nztnndk97Vr2R1JZzjP6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXA9gz4i7o6IlyPiqa55F0bEoxHxler/C6r5ERGfiIjDEfFkRFw6zM5Lknrr54z+HmD7SfN2Afszcwuwv5oGuBrYUv2bA+4YTDfL4jPqJa2lnkGfmY8D3zxp9nXA3ur1XuD6rvmfzI4DwPqIuHhQnZUkrV7dMfrJzDxWvX4RmKxebwBe6Gp3tJonSRqRyMzejSKmgIczc2s1/Wpmru9a/kpmXhARDwO7M/Nz1fz9wAcz8+AK25yjM7zD5OTkZfPz87UKWF5eZmJiota6q7W4dHyg29u2Yd0br9eyjmGxhnawhnZYixpmZ2cPZeZ0r3Z1H1P8UkRcnJnHqqGZl6v5S8CmrnYbq3lvkpl7gD0A09PTOTMzU6sjCwsL1F13tXYOeFz9yI0zb7xeyzqGxRrawRraoU011B262QfsqF7vAB7qmv/+6uqbK4DjXUM8kqQR6HlGHxH3ATPARRFxFPgwsBv4VETcBHwNeG/V/DPANcBh4FvAzw+hz5KkVegZ9Jn5vlMsumqFtgnc3LRTkqTB8c5YSSqcQS9JhTPoJalwBr0kFc6gl6TCGfSn4cPHJJXAoJekwhn0klS4us+6OaMMa/ime7v3bD9/KPuQJM/oJalwBr0kFc6gl6TCGfSSVDiDXpIKZ9BLUuG8vPIk3gkrqTSe0UtS4Qx6SSqcQS9JhTPoJalwjYI+In4jIr4UEU9FxH0R8daI2BwRT0TE4Yi4PyLeMqjOSpJWr3bQR8QG4NeA6czcCpwF3AB8FPh4Zr4deAW4aRAdlSTV03To5mzg3Ig4GzgPOAa8E3igWr4XuL7hPiRJDdQO+sxcAn4HeJ5OwB8HDgGvZuaJqtlRYEPTTkqS6ovMrLdixAXAp4H/DLwK/DGdM/nfqoZtiIhNwGeroZ2T158D5gAmJycvm5+fr9WP5eVlJiYmaq27ksWl4wPb1mpsXnfWQOsYhUEfi1Gwhnawhv7Mzs4eyszpXu2a3Bn708BXM/PrABHxIHAlsD4izq7O6jcCSyutnJl7gD0A09PTOTMzU6sTCwsL1F13JTtHdGfsLdtO8LHPvcaR3deOZP+DMOhjMQrW0A7WMFhNxuifB66IiPMiIoCrgKeBx4D3VG12AA816+KZxQ8klzRoTcbon6AzVPN5YLHa1h7gg8BvRsRh4G3AXQPopySppkYPNcvMDwMfPmn2c8DlTbar73242jgP50gaPe+MlaTCGfSSVDiDXpIKZ9BLUuEMekkqnEEvSYUz6CWpcAa9JBXOoJekwjW6M1Zry7tlJdXhGb0kFc6gl6TCGfSSVDiDXpIKZ9BLUuEMekkqnEEvSYUz6CWpcAa9JBWuUdBHxPqIeCAivhwRz0TET0bEhRHxaER8pfr/gkF1VpK0ek3P6G8H/iwzfxj4MeAZYBewPzO3APuraUnSiNQO+ohYB/wUcBdAZn4nM18FrgP2Vs32Atc37aQkqb4mZ/Sbga8DfxgRX4iIOyPifGAyM49VbV4EJpt2UpJUX2RmvRUjpoEDwJWZ+URE3A78A/Crmbm+q90rmfmmcfqImAPmACYnJy+bn5+v1Y/l5WUmJiZqrbuSxaXjA9vWakyeCy99u//22zasG15nahr0sRgFa2gHa+jP7Ozsocyc7tWuSdD/G+BAZk5V0/+Rznj824GZzDwWERcDC5n5jtNta3p6Og8ePFirHwsLC8zMzNRadyXdjwJeS7dsO8HHFvt/anQbH1M86GMxCtbQDtbQn4joK+hrD91k5ovACxHxeohfBTwN7AN2VPN2AA/V3YckqbmmHzzyq8C9EfEW4Dng5+n88vhURNwEfA14b8N9SJIaaBT0mflFYKU/G65qsl1J0uB4Z6wkFc6gl6TCGfSSVDiDXpIKZ9CPqaldj7zpmv+V5klS08srNWIGu6RePKOXpMIZ9JJUOINekgpn0EtS4Qx6SSqcQS9JhfPyyoqXKUoqlWf0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVrnHQR8RZEfGFiHi4mt4cEU9ExOGIuD8i3tK8m5KkugZxw9QHgGeAf11NfxT4eGbOR8QfADcBdwxgPwPnTVKSzgSNzugjYiNwLXBnNR3AO4EHqiZ7geub7EPN+KlTkpoO3fwecCvwL9X024BXM/NENX0U2NBwH5KkBiIz660Y8S7gmsz85YiYAf4LsBM4kJlvr9psAj6bmVtXWH8OmAOYnJy8bH5+vlY/lpeXmZiYqLXu4tLxWusNw+S58NK3h7f9bRvWDW/jlSbHoi2soR2soT+zs7OHMnO6V7smY/RXAu+OiGuAt9IZo78dWB8RZ1dn9RuBpZVWzsw9wB6A6enpnJmZqdWJhYUF6q67s0VDGrdsO8HHFof4jLnF1954eWT3tUPZRZNj0RbW0A7WMFi1h24y87bM3JiZU8ANwF9l5o3AY8B7qmY7gIca91KSVNswrqP/IPCbEXGYzpj9XUPYhySpTwMZK8jMBWChev0ccPkgtitJas47YyWpcAa9JBXOoD8DeROVdGY5Iz8z1pCTdCbxjF6SCmfQn8EcwpHODAa9JBXOoJekwp0xb8Y6RCHpTHXGBL2a6/5lOawHo0kaPIduJKlwBr0kFc6gl6TCGfSSVDiDXpIKZ9BLUuG8vFJeNikVzjN6SSqcQS9JhTPo9T18oqVUntpj9BGxCfgkMAkksCczb4+IC4H7gSngCPDezHyleVc1Kga/NN6anNGfAG7JzEuAK4CbI+ISYBewPzO3APuraUnSiNQO+sw8lpmfr17/I/AMsAG4DthbNdsLXN+0k5Kk+iIzm28kYgp4HNgKPJ+Z66v5Abzy+vRJ68wBcwCTk5OXzc/P19r38vIyExMTPdstLh2vtf21MnkuvPTtUfeif9s2rHvTvH6PRZtZQztYQ39mZ2cPZeZ0r3aNgz4iJoD/A3wkMx+MiFe7gz0iXsnMC063jenp6Tx48GCt/S8sLDAzM9OzXdvHmW/ZdoKPLY7PbQ0rXW/f77FoM2toB2voT0T0FfSNrrqJiO8DPg3cm5kPVrNfioiLq+UXAy832YfGx+LS8db/QpXORLWDvhqWuQt4JjN/t2vRPmBH9XoH8FD97kmSmmoyVnAl8HPAYkR8sZr3X4HdwKci4ibga8B7m3VRktRE7aDPzM8BcYrFV9XdrsbD60M0PhtHaj/vjJWkwo3PZR4aG6d7GqZPypTWnmf0klQ4g16SCmfQS1LhDHpJKpxBr6Hy+fbS6HnVjRrpDvFbtvXX7uR5Xn0jDZdn9JJUOINereJQjzR4Dt2oWN6cJXUY9Bo5z+Cl4XLoRpIKV/wZvWeLZVvt8IzDOToTFR/0KsewQrp7u/dsP39g25XawqEbSSqcZ/RqvdPdbNWk/bgM63ljmZoy6NVKdUJ4kMG90jCR4/saVw7dSFLhhnZGHxHbgduBs4A7M3P3MPazuHScnf5pqwHp/n7qxyCGVQZx5dD3PnPoBDt3PeLPg94wlKCPiLOA/wH8J+Ao8DcRsS8znx7G/k42LmOvKked77nTBfGg32c43S+kQQxJNdnGKH5ZnmmGdUZ/OXA4M58DiIh54DpgqEFvwGsYxvmN3NOpW1d3kPa7jdWG7+t/WRnagzGsMfoNwAtd00ereZKkNRaZOfiNRrwH2J6Zv1hN/xzw7zPzV7razAFz1eQ7gGdr7u4i4BsNutsWJdRhDe1gDe2wFjX828z8/l6NhjV0swRs6preWM17Q2buAfY03VFEHMzM6abbGbUS6rCGdrCGdmhTDcMauvkbYEtEbI6ItwA3APuGtC9J0mkM5Yw+M09ExK8Af07n8sq7M/NLw9iXJOn0hnYdfWZ+BvjMsLbfpfHwT0uUUIc1tIM1tENrahjKm7GSpPbwEQiSVLixDvqI2B4Rz0bE4YjYNer+9CMiNkXEYxHxdER8KSI+UM2/MCIejYivVP9fMOq+9hIRZ0XEFyLi4Wp6c0Q8UR2P+6s34lsrItZHxAMR8eWIeCYifnLcjkNE/Eb1ffRURNwXEW8dh+MQEXdHxMsR8VTXvBW/9tHxiaqeJyPi0tH1/LtOUcNvV99PT0bEn0TE+q5lt1U1PBsRP7uWfR3boO96zMLVwCXA+yLiktH2qi8ngFsy8xLgCuDmqt+7gP2ZuQXYX0233QeAZ7qmPwp8PDPfDrwC3DSSXvXvduDPMvOHgR+jU8vYHIeI2AD8GjCdmVvpXPhwA+NxHO4Btp8071Rf+6uBLdW/OeCONepjL/fw5hoeBbZm5o8CfwfcBlD9jN8A/Ei1zu9XGbYmxjbo6XrMQmZ+B3j9MQutlpnHMvPz1et/pBMuG+j0fW/VbC9w/Wh62J+I2AhcC9xZTQfwTuCBqkmra4iIdcBPAXcBZOZ3MvNVxuw40Lmg4tyIOBs4DzjGGByHzHwc+OZJs0/1tb8O+GR2HADWR8TFa9PTU1uphsz8i8w8UU0eoHMPEXRqmM/Mf8rMrwKH6WTYmhjnoB/7xyxExBTwE8ATwGRmHqsWvQhMjqhb/fo94FbgX6rptwGvdn2Tt/14bAa+DvxhNfx0Z0Sczxgdh8xcAn4HeJ5OwB8HDjFex6Hbqb724/qz/gvAZ6vXI61hnIN+rEXEBPBp4Ncz8x+6l2XnUqjWXg4VEe8CXs7MQ6PuSwNnA5cCd2TmTwCvcdIwzRgchwvonCluBn4QOJ83DyWMpbZ/7XuJiA/RGaa9d9R9gfEO+p6PWWiriPg+OiF/b2Y+WM1+6fU/R6v/Xx5V//pwJfDuiDhCZ8jsnXTGu9dXQwjQ/uNxFDiamU9U0w/QCf5xOg4/DXw1M7+emf8MPEjn2IzTceh2qq/9WP2sR8RO4F3Ajfnd69dHWsM4B/1YPmahGsu+C3gmM3+3a9E+YEf1egfw0Fr3rV+ZeVtmbszMKTpf97/KzBuBx4D3VM3aXsOLwAsR8Y5q1lV0HqM9NseBzpDNFRFxXvV99XoNY3McTnKqr/0+4P3V1TdXAMe7hnhaJTofuHQr8O7M/FbXon3ADRFxTkRspvPG8l+vWccyc2z/AdfQeWf774EPjbo/ffb5P9D5k/RJ4IvVv2vojHHvB74C/CVw4aj72mc9M8DD1et/V33zHgb+GDhn1P3r0fcfBw5Wx+JPgQvG7TgA/w34MvAU8L+Ac8bhOAD30Xlf4Z/p/HV106m+9kDQucLu74FFOlcZtbWGw3TG4l//2f6DrvYfqmp4Frh6LfvqnbGSVLhxHrqRJPXBoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXD/H/uzp/WcCE1mAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['tokens'] = df['desc_'].apply(text_to_word_sequence)\n",
    "lens = df['tokens'].apply(len)\n",
    "lens.hist(bins=[x for x in range(125)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteLowCount(t, threshold):\n",
    "    lcw = [w for w,c in t.word_counts.items() \n",
    "           if c < threshold  or w in all_names  or any(i.isdigit() for i in w)]\n",
    "    print(f\"{len(lcw)} low counted, {len(t.word_counts) - len(lcw)} left\")\n",
    "    for w in lcw:\n",
    "        del t.word_index[w]\n",
    "        del t.word_docs[w]\n",
    "        del t.word_counts[w]\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4417 low counted, 963 left\n"
     ]
    }
   ],
   "source": [
    "#Remove Stopwords\n",
    "df['tokens_sw'] = df['tokens'].apply(lambda d: [w for w in d if w not in stopwords])\n",
    "\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(df['tokens_sw'])\n",
    "t = deleteLowCount(t, 5)\n",
    "rT = dict(map(reversed, t.word_index.items()))\n",
    "df['sequence'] = t.texts_to_sequences(df['tokens_sw'])\n",
    "filtered = df['sequence'].apply(lambda x: [rT[num] for num in x])\n",
    "\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(filtered)\n",
    "df['sequence'] = t.texts_to_sequences(filtered)\n",
    "rT = dict(map(reversed, t.word_index.items()))\n",
    "numDistinctWords = len(t.word_index) + 1\n",
    "\n",
    "df['tokenized_common'] = df['sequence'].apply(lambda x: ' '.join([rT[num] for num in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = CountVectorizer(ngram_range=(1,7), analyzer='word')\n",
    "sparse_matrix = word_vectorizer.fit_transform(df['tokenized_common'])\n",
    "frequencies = sum(sparse_matrix).toarray()[0]\n",
    "freq = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequency    611\n",
      "Name: outside off, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(freq.loc['outside off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def get_feature_importances(model, analyzer, ngram_range=(1,2), lowercase=True, min_df=10, sampsize=2000, category='length_'):\n",
    "    tfv = TfidfVectorizer(min_df=min_df,\n",
    "                          strip_accents='unicode',\n",
    "                          analyzer=analyzer,\n",
    "                          ngram_range=ngram_range,\n",
    "                          lowercase=lowercase\n",
    "                         )\n",
    "    df_sample = df.sample(sampsize, random_state=seed)\n",
    "    X = tfv.fit_transform(df_sample.tokenized_common)\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    scaler.fit(X)\n",
    "    terms = tfv.get_feature_names()\n",
    "    var_imp = pd.DataFrame(index=terms)\n",
    "    #multiclassif\n",
    "    for cat in range(0,max(df_sample[category])+1):\n",
    "        y = df_sample[category].apply(lambda x: 1 if x == cat else 0).values\n",
    "        model.fit(X, y)\n",
    "        var_imp[cat] =  np.sqrt(scaler.var_) * model.coef_[0]\n",
    "        \n",
    "    var_imp['freq'] = pd.Series(var_imp.index.map(lambda x: freq.loc[x]['frequency']), index=var_imp.index) #Attach frequency of ngram to importance\n",
    "    return var_imp\n",
    "\n",
    "model = LogisticRegression()\n",
    "var_imp = get_feature_importances(model, analyzer='word', ngram_range=(2,6), lowercase=True, min_df=5, category='line_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>on off</th>\n",
       "      <td>-0.060913</td>\n",
       "      <td>-0.164970</td>\n",
       "      <td>0.182706</td>\n",
       "      <td>-0.035798</td>\n",
       "      <td>-0.015187</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>square leg</th>\n",
       "      <td>-0.050007</td>\n",
       "      <td>-0.163467</td>\n",
       "      <td>0.163482</td>\n",
       "      <td>0.005149</td>\n",
       "      <td>-0.011801</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mid on</th>\n",
       "      <td>-0.056661</td>\n",
       "      <td>-0.123761</td>\n",
       "      <td>0.160012</td>\n",
       "      <td>-0.036349</td>\n",
       "      <td>-0.009774</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off stump</th>\n",
       "      <td>-0.064595</td>\n",
       "      <td>-0.101067</td>\n",
       "      <td>0.146358</td>\n",
       "      <td>-0.049382</td>\n",
       "      <td>-0.022651</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on middle</th>\n",
       "      <td>-0.036263</td>\n",
       "      <td>-0.116866</td>\n",
       "      <td>0.135622</td>\n",
       "      <td>-0.027121</td>\n",
       "      <td>-0.007007</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep midwicket</th>\n",
       "      <td>-0.024710</td>\n",
       "      <td>-0.082388</td>\n",
       "      <td>0.105455</td>\n",
       "      <td>-0.018201</td>\n",
       "      <td>-0.004780</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full on</th>\n",
       "      <td>-0.031096</td>\n",
       "      <td>-0.086179</td>\n",
       "      <td>0.102273</td>\n",
       "      <td>-0.020976</td>\n",
       "      <td>-0.005731</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on off stump</th>\n",
       "      <td>-0.032802</td>\n",
       "      <td>-0.088507</td>\n",
       "      <td>0.100378</td>\n",
       "      <td>-0.024332</td>\n",
       "      <td>-0.006801</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length on</th>\n",
       "      <td>-0.026292</td>\n",
       "      <td>-0.077715</td>\n",
       "      <td>0.090802</td>\n",
       "      <td>-0.020308</td>\n",
       "      <td>-0.005482</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>through midwicket</th>\n",
       "      <td>-0.022706</td>\n",
       "      <td>-0.071481</td>\n",
       "      <td>0.089953</td>\n",
       "      <td>-0.018067</td>\n",
       "      <td>-0.003955</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fine leg</th>\n",
       "      <td>-0.032512</td>\n",
       "      <td>-0.124351</td>\n",
       "      <td>0.087125</td>\n",
       "      <td>0.068935</td>\n",
       "      <td>-0.010343</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>middle leg</th>\n",
       "      <td>-0.020688</td>\n",
       "      <td>-0.070677</td>\n",
       "      <td>0.084529</td>\n",
       "      <td>-0.015283</td>\n",
       "      <td>-0.003838</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on leg</th>\n",
       "      <td>-0.026782</td>\n",
       "      <td>-0.067202</td>\n",
       "      <td>0.081473</td>\n",
       "      <td>-0.004415</td>\n",
       "      <td>-0.006322</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on stumps</th>\n",
       "      <td>-0.023473</td>\n",
       "      <td>-0.077117</td>\n",
       "      <td>0.080730</td>\n",
       "      <td>0.007935</td>\n",
       "      <td>-0.003785</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on pads</th>\n",
       "      <td>-0.017748</td>\n",
       "      <td>-0.060100</td>\n",
       "      <td>0.075998</td>\n",
       "      <td>-0.015843</td>\n",
       "      <td>-0.003222</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short ball</th>\n",
       "      <td>-0.024863</td>\n",
       "      <td>-0.049374</td>\n",
       "      <td>0.071312</td>\n",
       "      <td>-0.019113</td>\n",
       "      <td>-0.006683</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>into leg</th>\n",
       "      <td>-0.015510</td>\n",
       "      <td>-0.045226</td>\n",
       "      <td>0.068152</td>\n",
       "      <td>-0.021110</td>\n",
       "      <td>-0.004795</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>into leg side</th>\n",
       "      <td>-0.013965</td>\n",
       "      <td>-0.041295</td>\n",
       "      <td>0.063452</td>\n",
       "      <td>-0.019997</td>\n",
       "      <td>-0.004446</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>over midwicket</th>\n",
       "      <td>-0.015055</td>\n",
       "      <td>-0.050526</td>\n",
       "      <td>0.063095</td>\n",
       "      <td>-0.009338</td>\n",
       "      <td>-0.002304</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep square</th>\n",
       "      <td>-0.016615</td>\n",
       "      <td>-0.045851</td>\n",
       "      <td>0.057673</td>\n",
       "      <td>-0.011952</td>\n",
       "      <td>-0.002963</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0         1         2         3         4  freq\n",
       "on off            -0.060913 -0.164970  0.182706 -0.035798 -0.015187  191 \n",
       "square leg        -0.050007 -0.163467  0.163482  0.005149 -0.011801  103 \n",
       "mid on            -0.056661 -0.123761  0.160012 -0.036349 -0.009774  85  \n",
       "off stump         -0.064595 -0.101067  0.146358 -0.049382 -0.022651  342 \n",
       "on middle         -0.036263 -0.116866  0.135622 -0.027121 -0.007007  95  \n",
       "deep midwicket    -0.024710 -0.082388  0.105455 -0.018201 -0.004780  30  \n",
       "full on           -0.031096 -0.086179  0.102273 -0.020976 -0.005731  71  \n",
       "on off stump      -0.032802 -0.088507  0.100378 -0.024332 -0.006801  106 \n",
       "length on         -0.026292 -0.077715  0.090802 -0.020308 -0.005482  96  \n",
       "through midwicket -0.022706 -0.071481  0.089953 -0.018067 -0.003955  23  \n",
       "fine leg          -0.032512 -0.124351  0.087125  0.068935 -0.010343  83  \n",
       "middle leg        -0.020688 -0.070677  0.084529 -0.015283 -0.003838  52  \n",
       "on leg            -0.026782 -0.067202  0.081473 -0.004415 -0.006322  63  \n",
       "on stumps         -0.023473 -0.077117  0.080730  0.007935 -0.003785  33  \n",
       "on pads           -0.017748 -0.060100  0.075998 -0.015843 -0.003222  30  \n",
       "short ball        -0.024863 -0.049374  0.071312 -0.019113 -0.006683  43  \n",
       "into leg          -0.015510 -0.045226  0.068152 -0.021110 -0.004795  32  \n",
       "into leg side     -0.013965 -0.041295  0.063452 -0.019997 -0.004446  30  \n",
       "over midwicket    -0.015055 -0.050526  0.063095 -0.009338 -0.002304  21  \n",
       "deep square       -0.016615 -0.045851  0.057673 -0.011952 -0.002963  34  "
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_imp.sort_values(2, ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174 important ngrams!\n"
     ]
    }
   ],
   "source": [
    "ngramsImportant = set()\n",
    "numTop = 40\n",
    "for l in range(0, len(var_imp.columns)-1):\n",
    "    sortedByL = var_imp.sort_values(l, ascending=False)\n",
    "    ngramsImportant.update(list(sortedByL.iloc[:numTop].index))\n",
    "print(f\"{len(ngramsImportant)} important ngrams!\")\n",
    "ngramsImportant = list(ngramsImportant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngramsInText(text):\n",
    "    ngramPresence = dict()\n",
    "    for ngram in ngramsImportant:\n",
    "        ngramSplit = ngram.split(' ')\n",
    "        ngramPresence[ngram] = int(tuple(ngramSplit) in set(nltk.ngrams(text.split(' '), len(ngramSplit))))\n",
    "    return pd.Series(ngramPresence)\n",
    "\n",
    "ngramPresenceDf = df['tokenized_common'].apply(lambda text: ngramsInText(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_</th>\n",
       "      <th>hand_</th>\n",
       "      <th>length_</th>\n",
       "      <th>line_</th>\n",
       "      <th>outcome_</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_sw</th>\n",
       "      <th>sequence</th>\n",
       "      <th>tokenized_common</th>\n",
       "      <th>change of</th>\n",
       "      <th>...</th>\n",
       "      <th>off back</th>\n",
       "      <th>off stump</th>\n",
       "      <th>side wide</th>\n",
       "      <th>pull shot</th>\n",
       "      <th>middle off</th>\n",
       "      <th>fine leg boundary</th>\n",
       "      <th>on up</th>\n",
       "      <th>wide length ball</th>\n",
       "      <th>of width</th>\n",
       "      <th>middle leg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steyn to Jaques, full and on the legs, swinging in, Jaques lets it go past, no runs, fielded by Boucher</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[steyn, to, jaques, full, and, on, the, legs, swinging, in, jaques, lets, it, go, past, no, runs, fielded, by, boucher]</td>\n",
       "      <td>[steyn, jaques, full, on, legs, swinging, in, jaques, lets, go, past, runs, fielded, boucher]</td>\n",
       "      <td>[14, 3, 479, 202, 5, 191, 68, 56, 50, 170]</td>\n",
       "      <td>full on legs swinging in lets go past runs fielded</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steyn to Jaques, good length but down leg, Jaques drives, no runs, fielded by Botha</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[steyn, to, jaques, good, length, but, down, leg, jaques, drives, no, runs, fielded, by, botha]</td>\n",
       "      <td>[steyn, jaques, good, length, down, leg, jaques, drives, runs, fielded, botha]</td>\n",
       "      <td>[15, 6, 16, 10, 69, 50, 170]</td>\n",
       "      <td>good length down leg drives runs fielded</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steyn to Jaques, short of a length outside the off stump, Jaques plays no shot, no runs, fielded by Boucher</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[steyn, to, jaques, short, of, a, length, outside, the, off, stump, jaques, plays, no, shot, no, runs, fielded, by, boucher]</td>\n",
       "      <td>[steyn, jaques, short, of, a, length, outside, off, stump, jaques, plays, shot, runs, fielded, boucher]</td>\n",
       "      <td>[11, 4, 1, 6, 7, 2, 12, 109, 62, 50, 170]</td>\n",
       "      <td>short of a length outside off stump plays shot runs fielded</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(no ball) Steyn to Jaques, good length delivery just outside the off stump, Jaques lets it go past, no runs, fielded by Boucher</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[no, ball, steyn, to, jaques, good, length, delivery, just, outside, the, off, stump, jaques, lets, it, go, past, no, runs, fielded, by, boucher]</td>\n",
       "      <td>[ball, steyn, jaques, good, length, delivery, outside, off, stump, jaques, lets, go, past, runs, fielded, boucher]</td>\n",
       "      <td>[8, 15, 6, 31, 7, 2, 12, 191, 68, 56, 50, 170]</td>\n",
       "      <td>ball good length delivery outside off stump lets go past runs fielded</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Steyn to Jaques, fuller length outside the off stump , Jaques drives in air over cover fielder, 4 runs</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>[steyn, to, jaques, fuller, length, outside, the, off, stump, jaques, drives, in, air, over, cover, fielder, 4, runs]</td>\n",
       "      <td>[steyn, jaques, fuller, length, outside, off, stump, jaques, drives, in, air, over, cover, fielder, 4, runs]</td>\n",
       "      <td>[64, 6, 7, 2, 12, 69, 5, 149, 27, 20, 115, 50]</td>\n",
       "      <td>fuller length outside off stump drives in air over cover fielder runs</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                              desc_  \\\n",
       "0   Steyn to Jaques, full and on the legs, swinging in, Jaques lets it go past, no runs, fielded by Boucher                           \n",
       "1   Steyn to Jaques, good length but down leg, Jaques drives, no runs, fielded by Botha                                               \n",
       "2   Steyn to Jaques, short of a length outside the off stump, Jaques plays no shot, no runs, fielded by Boucher                       \n",
       "3   (no ball) Steyn to Jaques, good length delivery just outside the off stump, Jaques lets it go past, no runs, fielded by Boucher   \n",
       "4   Steyn to Jaques, fuller length outside the off stump , Jaques drives in air over cover fielder, 4 runs                            \n",
       "\n",
       "   hand_  length_  line_  outcome_  \\\n",
       "0  1      2        2      0          \n",
       "1  1      3        3      0          \n",
       "2  1      4        1      0          \n",
       "3  1      3        1      4          \n",
       "4  1      2        1      12         \n",
       "\n",
       "                                                                                                                                              tokens  \\\n",
       "0  [steyn, to, jaques, full, and, on, the, legs, swinging, in, jaques, lets, it, go, past, no, runs, fielded, by, boucher]                             \n",
       "1  [steyn, to, jaques, good, length, but, down, leg, jaques, drives, no, runs, fielded, by, botha]                                                     \n",
       "2  [steyn, to, jaques, short, of, a, length, outside, the, off, stump, jaques, plays, no, shot, no, runs, fielded, by, boucher]                        \n",
       "3  [no, ball, steyn, to, jaques, good, length, delivery, just, outside, the, off, stump, jaques, lets, it, go, past, no, runs, fielded, by, boucher]   \n",
       "4  [steyn, to, jaques, fuller, length, outside, the, off, stump, jaques, drives, in, air, over, cover, fielder, 4, runs]                               \n",
       "\n",
       "                                                                                                            tokens_sw  \\\n",
       "0  [steyn, jaques, full, on, legs, swinging, in, jaques, lets, go, past, runs, fielded, boucher]                        \n",
       "1  [steyn, jaques, good, length, down, leg, jaques, drives, runs, fielded, botha]                                       \n",
       "2  [steyn, jaques, short, of, a, length, outside, off, stump, jaques, plays, shot, runs, fielded, boucher]              \n",
       "3  [ball, steyn, jaques, good, length, delivery, outside, off, stump, jaques, lets, go, past, runs, fielded, boucher]   \n",
       "4  [steyn, jaques, fuller, length, outside, off, stump, jaques, drives, in, air, over, cover, fielder, 4, runs]         \n",
       "\n",
       "                                         sequence  \\\n",
       "0  [14, 3, 479, 202, 5, 191, 68, 56, 50, 170]       \n",
       "1  [15, 6, 16, 10, 69, 50, 170]                     \n",
       "2  [11, 4, 1, 6, 7, 2, 12, 109, 62, 50, 170]        \n",
       "3  [8, 15, 6, 31, 7, 2, 12, 191, 68, 56, 50, 170]   \n",
       "4  [64, 6, 7, 2, 12, 69, 5, 149, 27, 20, 115, 50]   \n",
       "\n",
       "                                                        tokenized_common  \\\n",
       "0  full on legs swinging in lets go past runs fielded                      \n",
       "1  good length down leg drives runs fielded                                \n",
       "2  short of a length outside off stump plays shot runs fielded             \n",
       "3  ball good length delivery outside off stump lets go past runs fielded   \n",
       "4  fuller length outside off stump drives in air over cover fielder runs   \n",
       "\n",
       "   change of     ...      off back  off stump  side wide  pull shot  \\\n",
       "0  0             ...      0         0          0          0           \n",
       "1  0             ...      0         0          0          0           \n",
       "2  0             ...      0         1          0          0           \n",
       "3  0             ...      0         1          0          0           \n",
       "4  0             ...      0         1          0          0           \n",
       "\n",
       "   middle off  fine leg boundary  on up  wide length ball  of width  \\\n",
       "0  0           0                  0      0                 0          \n",
       "1  0           0                  0      0                 0          \n",
       "2  0           0                  0      0                 0          \n",
       "3  0           0                  0      0                 0          \n",
       "4  0           0                  0      0                 0          \n",
       "\n",
       "   middle leg  \n",
       "0  0           \n",
       "1  0           \n",
       "2  0           \n",
       "3  0           \n",
       "4  0           \n",
       "\n",
       "[5 rows x 183 columns]"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.reset_index(drop=True, inplace=True)\n",
    "# ngramPresenceDf.reset_index(drop=True, inplace=True)\n",
    "df_train = pd.concat([df, ngramPresenceDf], axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = ngramsImportant\n",
    "y_features = 'line_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2611, 174)\n"
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "# X, X_test, y, y_test = train_test_split(df_train[X_features], df_train[y_features], stratify = df_train[y_features], test_size=0.15, random_state=seed)\n",
    "# X, X_test = X.values, X_test.values\n",
    "# y = y.values\n",
    "\n",
    "X, y = df_train[X_features].values, df_train[y_features].values\n",
    "# pca = PCA(n_components=50)\n",
    "# X = pca.fit_transform(X)\n",
    "# print(np.cumsum(pca.explained_variance_ratio_))\n",
    "print(X.shape)\n",
    "# print(f\"X shape: {X.shape}, X_test shape: {X_test.shape}\\ny shape: {y.shape}, y_test.shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Linear SVM\", \"RBF SVM\", \"Decision Tree\", \"Random Forest\", \"Neural Net\"]\n",
    "\n",
    "classifiers = [\n",
    "    SVC(kernel=\"linear\", C=0.05),\n",
    "    SVC(gamma='scale', C=1),\n",
    "    DecisionTreeClassifier(max_depth=20),\n",
    "    RandomForestClassifier(max_depth=20, n_estimators=10, max_features=6),\n",
    "    MLPClassifier(alpha=1, max_iter=2000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Linear SVM - 0.73!\n",
      "Done RBF SVM - 0.76!\n",
      "Done Decision Tree - 0.76!\n",
      "Done Random Forest - 0.74!\n",
      "Done Neural Net - 0.80!\n"
     ]
    }
   ],
   "source": [
    "scores = defaultdict(list)\n",
    "for name, clf in zip(names, classifiers):\n",
    "    for i, (train_fold, test_fold) in enumerate(skf.split(X,y)):\n",
    "        train_x, test_x = X[train_fold], X[test_fold]\n",
    "        train_y, test_y = y[train_fold], y[test_fold]\n",
    "        clf.fit(train_x, train_y)\n",
    "        acc = clf.score(test_x, test_y)\n",
    "        scores[name].append(acc)\n",
    "    print(f\"Done {name} - {acc:<.2f}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, s in sorted(scores.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{name:<20} - {np.array(s).mean():<.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19894865, 0.19945377, 0.19238587, 0.19985362, 0.20935808])"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "weights = []\n",
    "for name, s in scores.items():\n",
    "    m = np.array(s).mean()\n",
    "    weights.append(m)\n",
    "weights = np.array(weights)\n",
    "weights = weights / weights.sum()\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 = 0.761!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 = 0.720!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 = 0.801!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 = 0.820!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-734-ad23b5921157>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifiers_ensemble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#         clf.class_weight = class_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mclf_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "names = [\"Linear SVM\", \"RBF SVM\", \"Decision Tree\", \"Random Forest\", \"Neural Net\"]\n",
    "\n",
    "classifiers_ensemble = [\n",
    "    SVC(kernel=\"linear\", C=0.05, probability=True),\n",
    "    SVC(gamma='scale', C=1, probability=True),\n",
    "    DecisionTreeClassifier(max_depth=20),\n",
    "    RandomForestClassifier(max_depth=20, n_estimators=10, max_features=6),\n",
    "    MLPClassifier(alpha=1, max_iter=2000)\n",
    "]\n",
    "\n",
    "scores_ensemble = []\n",
    "for i, (train_fold, test_fold) in enumerate(skf.split(X,y)):\n",
    "    train_x, test_x = X[train_fold], X[test_fold]\n",
    "    train_y, test_y = y[train_fold], y[test_fold]\n",
    "#     class_weights = class_weight.compute_class_weight('balanced', np.unique(train_y), np.ravel(train_y))\n",
    "#     class_weights = dict(enumerate(class_weights))\n",
    "    clf_preds = []\n",
    "    for i, (name, clf) in enumerate(zip(names, classifiers_ensemble)):\n",
    "#         clf.class_weight = class_weights\n",
    "        clf.fit(train_x, train_y)\n",
    "        clf_preds.append(clf.predict_proba(test_x))\n",
    "        \n",
    "    \n",
    "    clf_preds = np.array(clf_preds)\n",
    "    weighted_clf_preds = []\n",
    "    for idx, model in enumerate(clf_preds):\n",
    "        weighted_clf_preds.append(model * weights[idx])\n",
    "    weighted_clf_preds = np.array(weighted_clf_preds).sum(axis=0)\n",
    "    \n",
    "    clf_class_preds = weighted_clf_preds.argmax(axis=1)\n",
    "    report = classification_report(test_y, clf_class_preds, output_dict=True)\n",
    "    conf_mat = confusion_matrix(clf_class_preds, test_y)\n",
    "    acc = np.sum(conf_mat.diagonal()) / np.sum(conf_mat)\n",
    "    scores_ensemble.append([report, acc])\n",
    "    print(f\"Fold {i+1} = {acc:.3f}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Avg acc: {np.array([x[1] for x in scores_ensemble]).mean():>.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassPrecisions(scores):\n",
    "    classReport = {}\n",
    "    for lth in range(0, len(np.unique(train_y))):\n",
    "        classReport[lth] = {}\n",
    "        classReport[lth]['precision'] = 0\n",
    "        classReport[lth]['recall'] = 0\n",
    "        for report, acc in scores:\n",
    "            classReport[lth]['precision'] += report[str(lth)]['precision']\n",
    "            classReport[lth]['recall'] += report[str(lth)]['recall']\n",
    "        classReport[lth]['precision'] /= 10\n",
    "        classReport[lth]['recall'] /= 10\n",
    "    return classReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl, report in sorted(getClassPrecisions(scores_ensemble).items(), key=lambda x:x[1]['recall']):\n",
    "    print(f\"{cl:<1} | got {report['precision']*100:>5.1f}% right and found {report['recall']*100:>5.1f}% of the ones available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(classifiers_ensemble, \"model_list_trained\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

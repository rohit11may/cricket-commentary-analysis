{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import string\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "from random import randint, shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk import ngrams\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "pd.set_option('max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data!\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename):\n",
    "    with open(f\"{filename}.json\", \"rb\") as f:\n",
    "        data = json.load(f)\n",
    "    print(\"Loaded data!\")\n",
    "    return data\n",
    "        \n",
    "def load_df(filename):\n",
    "    with open(f\"{filename}.pkl\", \"rb\") as f:\n",
    "        d = pickle.load(f)\n",
    "    return d\n",
    "        \n",
    "def save_data(data, filename):\n",
    "    with open(f\"{filename}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "        \n",
    "def export_to_json(data):\n",
    "    with open('matches.json', 'w') as json_file:\n",
    "        json.dump(data, json_file)\n",
    "    \n",
    "i1b = lambda m : m['commentary']['innings1']['balls']\n",
    "i2b = lambda m : m['commentary']['innings2']['balls']\n",
    "i1o = lambda m : m['commentary']['innings1']['over_summaries']\n",
    "i2o = lambda m : m['commentary']['innings2']['over_summaries']\n",
    "df, players = load_df(\"dale_df\"), load_data('player_table')\n",
    "\n",
    "all_names = set()\n",
    "ambigNames = set(['short', 'ball', 'head', 'little', 'chase', 'cutting', 'cross'])\n",
    "for profile in players.values():\n",
    "    name = profile['known_as'].split(' ')\n",
    "    ambig = any(n.lower() in ambigNames for n in name)\n",
    "    if not ambig:\n",
    "        all_names.update(name)\n",
    "        all_names.update([n.lower() for n in name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "with open(\"glove.6B.100d.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_</th>\n",
       "      <th>hand_</th>\n",
       "      <th>length_</th>\n",
       "      <th>line_</th>\n",
       "      <th>outcome_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steyn to Jaques, full and on the legs, swinging in, Jaques lets it go past, no runs, fielded by Boucher</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steyn to Jaques, good length but down leg, Jaques drives, no runs, fielded by Botha</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steyn to Jaques, short of a length outside the off stump, Jaques plays no shot, no runs, fielded by Boucher</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(no ball) Steyn to Jaques, good length delivery just outside the off stump, Jaques lets it go past, no runs, fielded by Boucher</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Steyn to Jaques, fuller length outside the off stump , Jaques drives in air over cover fielder, 4 runs</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                              desc_  \\\n",
       "0   Steyn to Jaques, full and on the legs, swinging in, Jaques lets it go past, no runs, fielded by Boucher                           \n",
       "1   Steyn to Jaques, good length but down leg, Jaques drives, no runs, fielded by Botha                                               \n",
       "2   Steyn to Jaques, short of a length outside the off stump, Jaques plays no shot, no runs, fielded by Boucher                       \n",
       "3   (no ball) Steyn to Jaques, good length delivery just outside the off stump, Jaques lets it go past, no runs, fielded by Boucher   \n",
       "4   Steyn to Jaques, fuller length outside the off stump , Jaques drives in air over cover fielder, 4 runs                            \n",
       "\n",
       "   hand_  length_  line_  outcome_  \n",
       "0  1      2        2      0         \n",
       "1  1      3        3      0         \n",
       "2  1      4        1      0         \n",
       "3  1      3        1      4         \n",
       "4  1      2        1      12        "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords as st\n",
    "exceptions = ['a', 'off', 'against', 'between', 'into', 'through', 'above', 'below', 'up', 'down', 'out', 'in', 'over', 'further', 'on']\n",
    "stopwords = set(st.words('english'))\n",
    "for w in exceptions:\n",
    "    stopwords.remove(w) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1371b9cc0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['tokens'] = df['desc_'].apply(text_to_word_sequence)\n",
    "lens = df['tokens'].apply(len)\n",
    "lens.hist(bins=[x for x in range(125)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_</th>\n",
       "      <th>hand_</th>\n",
       "      <th>length_</th>\n",
       "      <th>line_</th>\n",
       "      <th>outcome_</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steyn to Jaques, full and on the legs, swinging in, Jaques lets it go past, no runs, fielded by Boucher</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[steyn, to, jaques, full, and, on, the, legs, swinging, in, jaques, lets, it, go, past, no, runs, fielded, by, boucher]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steyn to Jaques, good length but down leg, Jaques drives, no runs, fielded by Botha</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[steyn, to, jaques, good, length, but, down, leg, jaques, drives, no, runs, fielded, by, botha]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steyn to Jaques, short of a length outside the off stump, Jaques plays no shot, no runs, fielded by Boucher</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[steyn, to, jaques, short, of, a, length, outside, the, off, stump, jaques, plays, no, shot, no, runs, fielded, by, boucher]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(no ball) Steyn to Jaques, good length delivery just outside the off stump, Jaques lets it go past, no runs, fielded by Boucher</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[no, ball, steyn, to, jaques, good, length, delivery, just, outside, the, off, stump, jaques, lets, it, go, past, no, runs, fielded, by, boucher]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Steyn to Jaques, fuller length outside the off stump , Jaques drives in air over cover fielder, 4 runs</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>[steyn, to, jaques, fuller, length, outside, the, off, stump, jaques, drives, in, air, over, cover, fielder, 4, runs]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                              desc_  \\\n",
       "0   Steyn to Jaques, full and on the legs, swinging in, Jaques lets it go past, no runs, fielded by Boucher                           \n",
       "1   Steyn to Jaques, good length but down leg, Jaques drives, no runs, fielded by Botha                                               \n",
       "2   Steyn to Jaques, short of a length outside the off stump, Jaques plays no shot, no runs, fielded by Boucher                       \n",
       "3   (no ball) Steyn to Jaques, good length delivery just outside the off stump, Jaques lets it go past, no runs, fielded by Boucher   \n",
       "4   Steyn to Jaques, fuller length outside the off stump , Jaques drives in air over cover fielder, 4 runs                            \n",
       "\n",
       "   hand_  length_  line_  outcome_  \\\n",
       "0  1      2        2      0          \n",
       "1  1      3        3      0          \n",
       "2  1      4        1      0          \n",
       "3  1      3        1      4          \n",
       "4  1      2        1      12         \n",
       "\n",
       "                                                                                                                                              tokens  \n",
       "0  [steyn, to, jaques, full, and, on, the, legs, swinging, in, jaques, lets, it, go, past, no, runs, fielded, by, boucher]                            \n",
       "1  [steyn, to, jaques, good, length, but, down, leg, jaques, drives, no, runs, fielded, by, botha]                                                    \n",
       "2  [steyn, to, jaques, short, of, a, length, outside, the, off, stump, jaques, plays, no, shot, no, runs, fielded, by, boucher]                       \n",
       "3  [no, ball, steyn, to, jaques, good, length, delivery, just, outside, the, off, stump, jaques, lets, it, go, past, no, runs, fielded, by, boucher]  \n",
       "4  [steyn, to, jaques, fuller, length, outside, the, off, stump, jaques, drives, in, air, over, cover, fielder, 4, runs]                              "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Stopwords\n",
    "df['tokens_sw'] = df['tokens'].apply(lambda d: [w for w in d if w not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmas = []\n",
    "    for w, tag in nltk.pos_tag(text):\n",
    "        wntag = tag[0].lower()\n",
    "        wntag = wntag if wntag in ['a', 'r', 'n', 'v'] else None\n",
    "        lemmas.append(lemmatizer.lemmatize(w, wntag) if wntag else w)\n",
    "    return lemmas\n",
    "\n",
    "df['lemmatized'] = df['tokens_sw'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "sno = nltk.stem.PorterStemmer()\n",
    "df['stemmed'] = df['lemmatized'].apply(lambda text: [sno.stem(w) for w in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteLowCount(t, threshold):\n",
    "    lcw = [w for w,c in t.word_counts.items() \n",
    "           if c < threshold  or w in all_names  or any(i.isdigit() for i in w)]\n",
    "    print(f\"{len(lcw)} low counted, {len(t.word_counts) - len(lcw)} left\")\n",
    "    for w in lcw:\n",
    "        del t.word_index[w]\n",
    "        del t.word_docs[w]\n",
    "        del t.word_counts[w]\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3704 low counted, 829 left\n"
     ]
    }
   ],
   "source": [
    "col_to_tokenize = 'lemmatized'\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(df[col_to_tokenize])\n",
    "t = deleteLowCount(t, 5)\n",
    "rT = dict(map(reversed, t.word_index.items()))\n",
    "df['sequence'] = t.texts_to_sequences(df[col_to_tokenize])\n",
    "filtered = df['sequence'].apply(lambda x: [rT[num] for num in x])\n",
    "\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(filtered)\n",
    "df['sequence'] = t.texts_to_sequences(filtered)\n",
    "rT = dict(map(reversed, t.word_index.items()))\n",
    "numDistinctWords = len(t.word_index) + 1\n",
    "\n",
    "df[f'{col_to_tokenize}_common'] = df['sequence'].apply(lambda x: ' '.join([rT[num] for num in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentenceVector(tokens):\n",
    "    tokens = tokens.split(' ')\n",
    "    vectors = np.empty(len(embeddings_dict['hello']))\n",
    "    for word in tokens:\n",
    "        if word in embeddings_dict:\n",
    "            vectors += embeddings_dict[word]\n",
    "    vectors /= len(tokens)\n",
    "    return pd.Series({i:num for i, num in enumerate(vectors)})\n",
    "\n",
    "vectors = df['lemmatized_common'].apply(getSentenceVector)\n",
    "df_train_vectors = pd.concat([df, vectors], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2611.000000</td>\n",
       "      <td>2611.000000</td>\n",
       "      <td>2611.000000</td>\n",
       "      <td>2611.000000</td>\n",
       "      <td>2611.000000</td>\n",
       "      <td>2611.000000</td>\n",
       "      <td>2611.000000</td>\n",
       "      <td>2611.000000</td>\n",
       "      <td>2611.000000</td>\n",
       "      <td>2611.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2611.000000</td>\n",
       "      <td>2611.000000</td>\n",
       "      <td>2611.000000</td>\n",
       "      <td>2611.000000</td>\n",
       "      <td>2611.000000</td>\n",
       "      <td>2611.000000</td>\n",
       "      <td>2611.000000</td>\n",
       "      <td>2611.000000</td>\n",
       "      <td>2611.000000</td>\n",
       "      <td>2611.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.201673</td>\n",
       "      <td>0.119058</td>\n",
       "      <td>0.275464</td>\n",
       "      <td>-0.220498</td>\n",
       "      <td>-0.007588</td>\n",
       "      <td>0.257129</td>\n",
       "      <td>-0.122045</td>\n",
       "      <td>0.230177</td>\n",
       "      <td>-0.404370</td>\n",
       "      <td>0.042741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165947</td>\n",
       "      <td>0.054733</td>\n",
       "      <td>-0.230614</td>\n",
       "      <td>-0.072550</td>\n",
       "      <td>-0.428206</td>\n",
       "      <td>-0.038945</td>\n",
       "      <td>-0.021182</td>\n",
       "      <td>0.084071</td>\n",
       "      <td>0.547048</td>\n",
       "      <td>0.095948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.108493</td>\n",
       "      <td>0.115964</td>\n",
       "      <td>0.109863</td>\n",
       "      <td>0.125306</td>\n",
       "      <td>0.140860</td>\n",
       "      <td>0.142366</td>\n",
       "      <td>0.142238</td>\n",
       "      <td>0.130255</td>\n",
       "      <td>0.154283</td>\n",
       "      <td>0.105881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141761</td>\n",
       "      <td>0.114313</td>\n",
       "      <td>0.136619</td>\n",
       "      <td>0.144533</td>\n",
       "      <td>0.135473</td>\n",
       "      <td>0.117837</td>\n",
       "      <td>0.114679</td>\n",
       "      <td>0.147241</td>\n",
       "      <td>0.160226</td>\n",
       "      <td>0.124421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.853547</td>\n",
       "      <td>-0.617757</td>\n",
       "      <td>-0.349129</td>\n",
       "      <td>-1.226950</td>\n",
       "      <td>-1.184924</td>\n",
       "      <td>-0.262733</td>\n",
       "      <td>-1.285762</td>\n",
       "      <td>-0.576938</td>\n",
       "      <td>-1.268513</td>\n",
       "      <td>-0.454056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.823524</td>\n",
       "      <td>-0.463292</td>\n",
       "      <td>-0.796642</td>\n",
       "      <td>-0.926966</td>\n",
       "      <td>-1.391976</td>\n",
       "      <td>-0.569309</td>\n",
       "      <td>-0.682432</td>\n",
       "      <td>-0.586456</td>\n",
       "      <td>-0.123845</td>\n",
       "      <td>-0.538853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.266881</td>\n",
       "      <td>0.049984</td>\n",
       "      <td>0.205982</td>\n",
       "      <td>-0.297745</td>\n",
       "      <td>-0.093417</td>\n",
       "      <td>0.166417</td>\n",
       "      <td>-0.200103</td>\n",
       "      <td>0.153803</td>\n",
       "      <td>-0.495486</td>\n",
       "      <td>-0.023972</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248683</td>\n",
       "      <td>-0.012919</td>\n",
       "      <td>-0.318270</td>\n",
       "      <td>-0.161102</td>\n",
       "      <td>-0.503764</td>\n",
       "      <td>-0.112846</td>\n",
       "      <td>-0.094344</td>\n",
       "      <td>-0.007644</td>\n",
       "      <td>0.444085</td>\n",
       "      <td>0.019808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.198392</td>\n",
       "      <td>0.123729</td>\n",
       "      <td>0.276799</td>\n",
       "      <td>-0.218581</td>\n",
       "      <td>-0.003908</td>\n",
       "      <td>0.258380</td>\n",
       "      <td>-0.113904</td>\n",
       "      <td>0.227753</td>\n",
       "      <td>-0.399558</td>\n",
       "      <td>0.041590</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.160875</td>\n",
       "      <td>0.056524</td>\n",
       "      <td>-0.228612</td>\n",
       "      <td>-0.068599</td>\n",
       "      <td>-0.427412</td>\n",
       "      <td>-0.037477</td>\n",
       "      <td>-0.019684</td>\n",
       "      <td>0.073752</td>\n",
       "      <td>0.540714</td>\n",
       "      <td>0.099241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.134052</td>\n",
       "      <td>0.189363</td>\n",
       "      <td>0.343350</td>\n",
       "      <td>-0.143289</td>\n",
       "      <td>0.078842</td>\n",
       "      <td>0.348332</td>\n",
       "      <td>-0.033734</td>\n",
       "      <td>0.309837</td>\n",
       "      <td>-0.304488</td>\n",
       "      <td>0.107543</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073198</td>\n",
       "      <td>0.125390</td>\n",
       "      <td>-0.145432</td>\n",
       "      <td>0.018744</td>\n",
       "      <td>-0.351012</td>\n",
       "      <td>0.035516</td>\n",
       "      <td>0.048744</td>\n",
       "      <td>0.166964</td>\n",
       "      <td>0.649328</td>\n",
       "      <td>0.172838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.266351</td>\n",
       "      <td>0.767164</td>\n",
       "      <td>0.766122</td>\n",
       "      <td>0.228927</td>\n",
       "      <td>0.540636</td>\n",
       "      <td>1.070654</td>\n",
       "      <td>0.486679</td>\n",
       "      <td>0.753263</td>\n",
       "      <td>0.150037</td>\n",
       "      <td>0.909342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429562</td>\n",
       "      <td>0.569936</td>\n",
       "      <td>0.377705</td>\n",
       "      <td>0.536286</td>\n",
       "      <td>0.633283</td>\n",
       "      <td>0.448927</td>\n",
       "      <td>0.587452</td>\n",
       "      <td>1.373579</td>\n",
       "      <td>1.129232</td>\n",
       "      <td>0.611816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2            3            4  \\\n",
       "count  2611.000000  2611.000000  2611.000000  2611.000000  2611.000000   \n",
       "mean  -0.201673     0.119058     0.275464    -0.220498    -0.007588      \n",
       "std    0.108493     0.115964     0.109863     0.125306     0.140860      \n",
       "min   -0.853547    -0.617757    -0.349129    -1.226950    -1.184924      \n",
       "25%   -0.266881     0.049984     0.205982    -0.297745    -0.093417      \n",
       "50%   -0.198392     0.123729     0.276799    -0.218581    -0.003908      \n",
       "75%   -0.134052     0.189363     0.343350    -0.143289     0.078842      \n",
       "max    0.266351     0.767164     0.766122     0.228927     0.540636      \n",
       "\n",
       "                 5            6            7            8            9  \\\n",
       "count  2611.000000  2611.000000  2611.000000  2611.000000  2611.000000   \n",
       "mean   0.257129    -0.122045     0.230177    -0.404370     0.042741      \n",
       "std    0.142366     0.142238     0.130255     0.154283     0.105881      \n",
       "min   -0.262733    -1.285762    -0.576938    -1.268513    -0.454056      \n",
       "25%    0.166417    -0.200103     0.153803    -0.495486    -0.023972      \n",
       "50%    0.258380    -0.113904     0.227753    -0.399558     0.041590      \n",
       "75%    0.348332    -0.033734     0.309837    -0.304488     0.107543      \n",
       "max    1.070654     0.486679     0.753263     0.150037     0.909342      \n",
       "\n",
       "          ...                90           91           92           93  \\\n",
       "count     ...       2611.000000  2611.000000  2611.000000  2611.000000   \n",
       "mean      ...      -0.165947     0.054733    -0.230614    -0.072550      \n",
       "std       ...       0.141761     0.114313     0.136619     0.144533      \n",
       "min       ...      -0.823524    -0.463292    -0.796642    -0.926966      \n",
       "25%       ...      -0.248683    -0.012919    -0.318270    -0.161102      \n",
       "50%       ...      -0.160875     0.056524    -0.228612    -0.068599      \n",
       "75%       ...      -0.073198     0.125390    -0.145432     0.018744      \n",
       "max       ...       0.429562     0.569936     0.377705     0.536286      \n",
       "\n",
       "                94           95           96           97           98  \\\n",
       "count  2611.000000  2611.000000  2611.000000  2611.000000  2611.000000   \n",
       "mean  -0.428206    -0.038945    -0.021182     0.084071     0.547048      \n",
       "std    0.135473     0.117837     0.114679     0.147241     0.160226      \n",
       "min   -1.391976    -0.569309    -0.682432    -0.586456    -0.123845      \n",
       "25%   -0.503764    -0.112846    -0.094344    -0.007644     0.444085      \n",
       "50%   -0.427412    -0.037477    -0.019684     0.073752     0.540714      \n",
       "75%   -0.351012     0.035516     0.048744     0.166964     0.649328      \n",
       "max    0.633283     0.448927     0.587452     1.373579     1.129232      \n",
       "\n",
       "                99  \n",
       "count  2611.000000  \n",
       "mean   0.095948     \n",
       "std    0.124421     \n",
       "min   -0.538853     \n",
       "25%    0.019808     \n",
       "50%    0.099241     \n",
       "75%    0.172838     \n",
       "max    0.611816     \n",
       "\n",
       "[8 rows x 100 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = CountVectorizer(ngram_range=(1,6), analyzer='word')\n",
    "sparse_matrix = word_vectorizer.fit_transform(df[f'{col_to_tokenize}_common'])\n",
    "frequencies = sum(sparse_matrix).toarray()[0]\n",
    "freq = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def get_feature_importances(model, analyzer, ngram_range=(1,2), lowercase=True, min_df=10, max_df=1000, sampsize=2419, category='length_'):\n",
    "    tfv = TfidfVectorizer(min_df=min_df,\n",
    "                          max_df=max_df,\n",
    "                          strip_accents='unicode',\n",
    "                          analyzer=analyzer,\n",
    "                          ngram_range=ngram_range,\n",
    "                          lowercase=lowercase\n",
    "                         )\n",
    "    df_sample = df.sample(sampsize, random_state=seed)\n",
    "    X = tfv.fit_transform(df_sample[f'{col_to_tokenize}_common'])\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    scaler.fit(X)\n",
    "    terms = tfv.get_feature_names()\n",
    "    var_imp = pd.DataFrame(index=terms)\n",
    "    #multiclassif\n",
    "    for cat in range(0,max(df_sample[category])+1):\n",
    "        y = df_sample[category].apply(lambda x: 1 if x == cat else 0).values\n",
    "        model.fit(X, y)\n",
    "        var_imp[cat] =  np.sqrt(scaler.var_) * model.coef_[0]\n",
    "        \n",
    "    var_imp['freq'] = pd.Series(var_imp.index.map(lambda x: freq.loc[x]['frequency']), index=var_imp.index) #Attach frequency of ngram to importance\n",
    "    return var_imp\n",
    "\n",
    "model = LogisticRegression()\n",
    "cat = 'length_'\n",
    "var_imp16 = get_feature_importances(model, analyzer='word', ngram_range=(1,6), lowercase=True, min_df=5, category=cat)\n",
    "var_imp26 = get_feature_importances(model, analyzer='word', ngram_range=(2,6), lowercase=True, min_df=5, category=cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>full on</th>\n",
       "      <td>-0.009542</td>\n",
       "      <td>-0.022249</td>\n",
       "      <td>0.178924</td>\n",
       "      <td>-0.103920</td>\n",
       "      <td>-0.065971</td>\n",
       "      <td>-0.058304</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full outside</th>\n",
       "      <td>-0.007687</td>\n",
       "      <td>-0.013358</td>\n",
       "      <td>0.129103</td>\n",
       "      <td>-0.081208</td>\n",
       "      <td>-0.041875</td>\n",
       "      <td>-0.050198</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full outside off</th>\n",
       "      <td>-0.007687</td>\n",
       "      <td>-0.013358</td>\n",
       "      <td>0.129103</td>\n",
       "      <td>-0.081208</td>\n",
       "      <td>-0.041875</td>\n",
       "      <td>-0.050198</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mid off</th>\n",
       "      <td>-0.000739</td>\n",
       "      <td>-0.034994</td>\n",
       "      <td>0.121705</td>\n",
       "      <td>-0.027739</td>\n",
       "      <td>-0.082316</td>\n",
       "      <td>-0.077756</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full wide</th>\n",
       "      <td>-0.005226</td>\n",
       "      <td>-0.010127</td>\n",
       "      <td>0.121439</td>\n",
       "      <td>-0.073660</td>\n",
       "      <td>-0.040803</td>\n",
       "      <td>-0.034146</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mid on</th>\n",
       "      <td>0.008973</td>\n",
       "      <td>-0.027713</td>\n",
       "      <td>0.110383</td>\n",
       "      <td>-0.058059</td>\n",
       "      <td>-0.043642</td>\n",
       "      <td>-0.038238</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off pad</th>\n",
       "      <td>-0.005763</td>\n",
       "      <td>-0.010449</td>\n",
       "      <td>0.095134</td>\n",
       "      <td>-0.043069</td>\n",
       "      <td>-0.030761</td>\n",
       "      <td>-0.036621</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slower ball</th>\n",
       "      <td>-0.009645</td>\n",
       "      <td>0.018376</td>\n",
       "      <td>0.088870</td>\n",
       "      <td>-0.041944</td>\n",
       "      <td>-0.044245</td>\n",
       "      <td>-0.049427</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>front foot</th>\n",
       "      <td>-0.008500</td>\n",
       "      <td>-0.015881</td>\n",
       "      <td>0.087978</td>\n",
       "      <td>-0.035743</td>\n",
       "      <td>-0.040644</td>\n",
       "      <td>-0.040220</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>down leg</th>\n",
       "      <td>-0.004437</td>\n",
       "      <td>-0.007351</td>\n",
       "      <td>0.079826</td>\n",
       "      <td>-0.058902</td>\n",
       "      <td>-0.079806</td>\n",
       "      <td>0.027658</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0         1         2         3         4         5  \\\n",
       "full on          -0.009542 -0.022249  0.178924 -0.103920 -0.065971 -0.058304   \n",
       "full outside     -0.007687 -0.013358  0.129103 -0.081208 -0.041875 -0.050198   \n",
       "full outside off -0.007687 -0.013358  0.129103 -0.081208 -0.041875 -0.050198   \n",
       "mid off          -0.000739 -0.034994  0.121705 -0.027739 -0.082316 -0.077756   \n",
       "full wide        -0.005226 -0.010127  0.121439 -0.073660 -0.040803 -0.034146   \n",
       "mid on            0.008973 -0.027713  0.110383 -0.058059 -0.043642 -0.038238   \n",
       "off pad          -0.005763 -0.010449  0.095134 -0.043069 -0.030761 -0.036621   \n",
       "slower ball      -0.009645  0.018376  0.088870 -0.041944 -0.044245 -0.049427   \n",
       "front foot       -0.008500 -0.015881  0.087978 -0.035743 -0.040644 -0.040220   \n",
       "down leg         -0.004437 -0.007351  0.079826 -0.058902 -0.079806  0.027658   \n",
       "\n",
       "                  freq  \n",
       "full on           71    \n",
       "full outside      61    \n",
       "full outside off  61    \n",
       "mid off           125   \n",
       "full wide         31    \n",
       "mid on            85    \n",
       "off pad           29    \n",
       "slower ball       53    \n",
       "front foot        75    \n",
       "down leg          84    "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_imp26.sort_values(2, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412 important ngrams!\n"
     ]
    }
   ],
   "source": [
    "ngramsImportant = set()\n",
    "numTop16 = 50\n",
    "numTop26 = 50\n",
    "for l in range(0, len(var_imp16.columns)-1):\n",
    "    sortedByL16 = var_imp16.sort_values(l, ascending=False)\n",
    "    sortedByL26 = var_imp26.sort_values(l, ascending=False)\n",
    "    ngramsImportant.update(list(sortedByL16.iloc[:numTop16].index))\n",
    "    ngramsImportant.update(list(sortedByL26.iloc[:numTop26].index))\n",
    "print(f\"{len(ngramsImportant)} important ngrams!\")\n",
    "ngramsImportant = list(ngramsImportant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngramsInText(text):\n",
    "    ngramPresence = dict()\n",
    "    for ngram in ngramsImportant:\n",
    "        ngramSplit = ngram.split(' ')\n",
    "        ngramPresence[ngram] = int(tuple(ngramSplit) in set(nltk.ngrams(text.split(' '), len(ngramSplit))))\n",
    "    return pd.Series(ngramPresence)\n",
    "\n",
    "ngramPresenceDf = df[f'{col_to_tokenize}_common'].apply(lambda text: ngramsInText(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_</th>\n",
       "      <th>hand_</th>\n",
       "      <th>length_</th>\n",
       "      <th>line_</th>\n",
       "      <th>outcome_</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_sw</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>sequence</th>\n",
       "      <th>lemmatized_common</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steyn to Jaques, full and on the legs, swinging in, Jaques lets it go past, no runs, fielded by Boucher</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[steyn, to, jaques, full, and, on, the, legs, swinging, in, jaques, lets, it, go, past, no, runs, fielded, by, boucher]</td>\n",
       "      <td>[steyn, jaques, full, on, legs, swinging, in, jaques, lets, go, past, runs, fielded, boucher]</td>\n",
       "      <td>[steyn, jaques, full, on, leg, swing, in, jaques, let, go, past, run, field, boucher]</td>\n",
       "      <td>[14, 3, 9, 54, 4, 124, 20, 68, 29, 89]</td>\n",
       "      <td>full on leg swing in let go past run field</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208410</td>\n",
       "      <td>0.027172</td>\n",
       "      <td>-0.236194</td>\n",
       "      <td>0.126792</td>\n",
       "      <td>-0.473070</td>\n",
       "      <td>0.022373</td>\n",
       "      <td>0.030191</td>\n",
       "      <td>0.081813</td>\n",
       "      <td>0.545245</td>\n",
       "      <td>0.132145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steyn to Jaques, good length but down leg, Jaques drives, no runs, fielded by Botha</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[steyn, to, jaques, good, length, but, down, leg, jaques, drives, no, runs, fielded, by, botha]</td>\n",
       "      <td>[steyn, jaques, good, length, down, leg, jaques, drives, runs, fielded, botha]</td>\n",
       "      <td>[steyn, jaques, good, length, down, leg, jaques, drive, run, field, botha]</td>\n",
       "      <td>[16, 5, 17, 9, 22, 29, 89]</td>\n",
       "      <td>good length down leg drive run field</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.361614</td>\n",
       "      <td>-0.087467</td>\n",
       "      <td>-0.298755</td>\n",
       "      <td>-0.052747</td>\n",
       "      <td>-0.529953</td>\n",
       "      <td>-0.011515</td>\n",
       "      <td>0.070159</td>\n",
       "      <td>0.023637</td>\n",
       "      <td>0.693554</td>\n",
       "      <td>0.168549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steyn to Jaques, short of a length outside the off stump, Jaques plays no shot, no runs, fielded by Boucher</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[steyn, to, jaques, short, of, a, length, outside, the, off, stump, jaques, plays, no, shot, no, runs, fielded, by, boucher]</td>\n",
       "      <td>[steyn, jaques, short, a, length, outside, off, stump, jaques, plays, shot, runs, fielded, boucher]</td>\n",
       "      <td>[steyn, jaques, short, a, length, outside, off, stump, jaques, play, shoot, run, field, boucher]</td>\n",
       "      <td>[12, 1, 5, 7, 2, 10, 41, 431, 29, 89]</td>\n",
       "      <td>short a length outside off stump play shoot run field</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133592</td>\n",
       "      <td>-0.047485</td>\n",
       "      <td>-0.200691</td>\n",
       "      <td>-0.206948</td>\n",
       "      <td>-0.420979</td>\n",
       "      <td>-0.022429</td>\n",
       "      <td>-0.015349</td>\n",
       "      <td>0.145458</td>\n",
       "      <td>0.567531</td>\n",
       "      <td>0.241330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(no ball) Steyn to Jaques, good length delivery just outside the off stump, Jaques lets it go past, no runs, fielded by Boucher</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[no, ball, steyn, to, jaques, good, length, delivery, just, outside, the, off, stump, jaques, lets, it, go, past, no, runs, fielded, by, boucher]</td>\n",
       "      <td>[ball, steyn, jaques, good, length, delivery, outside, off, stump, jaques, lets, go, past, runs, fielded, boucher]</td>\n",
       "      <td>[ball, steyn, jaques, good, length, delivery, outside, off, stump, jaques, let, go, past, run, field, boucher]</td>\n",
       "      <td>[6, 16, 5, 36, 7, 2, 10, 124, 20, 68, 29, 89]</td>\n",
       "      <td>ball good length delivery outside off stump let go past run field</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198405</td>\n",
       "      <td>0.021079</td>\n",
       "      <td>-0.183381</td>\n",
       "      <td>-0.171802</td>\n",
       "      <td>-0.501083</td>\n",
       "      <td>-0.044090</td>\n",
       "      <td>0.078121</td>\n",
       "      <td>0.231797</td>\n",
       "      <td>0.435399</td>\n",
       "      <td>0.297424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Steyn to Jaques, fuller length outside the off stump , Jaques drives in air over cover fielder, 4 runs</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>[steyn, to, jaques, fuller, length, outside, the, off, stump, jaques, drives, in, air, over, cover, fielder, 4, runs]</td>\n",
       "      <td>[steyn, jaques, fuller, length, outside, off, stump, jaques, drives, in, air, over, cover, fielder, 4, runs]</td>\n",
       "      <td>[steyn, jaques, fuller, length, outside, off, stump, jaques, drive, in, air, over, cover, fielder, 4, run]</td>\n",
       "      <td>[80, 5, 7, 2, 10, 22, 4, 165, 23, 15, 105, 29]</td>\n",
       "      <td>fuller length outside off stump drive in air over cover fielder run</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009995</td>\n",
       "      <td>-0.100273</td>\n",
       "      <td>-0.312664</td>\n",
       "      <td>-0.169811</td>\n",
       "      <td>-0.413796</td>\n",
       "      <td>0.154531</td>\n",
       "      <td>0.028461</td>\n",
       "      <td>0.172708</td>\n",
       "      <td>0.572854</td>\n",
       "      <td>0.015922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 522 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                              desc_  \\\n",
       "0   Steyn to Jaques, full and on the legs, swinging in, Jaques lets it go past, no runs, fielded by Boucher                           \n",
       "1   Steyn to Jaques, good length but down leg, Jaques drives, no runs, fielded by Botha                                               \n",
       "2   Steyn to Jaques, short of a length outside the off stump, Jaques plays no shot, no runs, fielded by Boucher                       \n",
       "3   (no ball) Steyn to Jaques, good length delivery just outside the off stump, Jaques lets it go past, no runs, fielded by Boucher   \n",
       "4   Steyn to Jaques, fuller length outside the off stump , Jaques drives in air over cover fielder, 4 runs                            \n",
       "\n",
       "   hand_  length_  line_  outcome_  \\\n",
       "0  1      2        2      0          \n",
       "1  1      3        3      0          \n",
       "2  1      4        1      0          \n",
       "3  1      3        1      4          \n",
       "4  1      2        1      12         \n",
       "\n",
       "                                                                                                                                              tokens  \\\n",
       "0  [steyn, to, jaques, full, and, on, the, legs, swinging, in, jaques, lets, it, go, past, no, runs, fielded, by, boucher]                             \n",
       "1  [steyn, to, jaques, good, length, but, down, leg, jaques, drives, no, runs, fielded, by, botha]                                                     \n",
       "2  [steyn, to, jaques, short, of, a, length, outside, the, off, stump, jaques, plays, no, shot, no, runs, fielded, by, boucher]                        \n",
       "3  [no, ball, steyn, to, jaques, good, length, delivery, just, outside, the, off, stump, jaques, lets, it, go, past, no, runs, fielded, by, boucher]   \n",
       "4  [steyn, to, jaques, fuller, length, outside, the, off, stump, jaques, drives, in, air, over, cover, fielder, 4, runs]                               \n",
       "\n",
       "                                                                                                            tokens_sw  \\\n",
       "0  [steyn, jaques, full, on, legs, swinging, in, jaques, lets, go, past, runs, fielded, boucher]                        \n",
       "1  [steyn, jaques, good, length, down, leg, jaques, drives, runs, fielded, botha]                                       \n",
       "2  [steyn, jaques, short, a, length, outside, off, stump, jaques, plays, shot, runs, fielded, boucher]                  \n",
       "3  [ball, steyn, jaques, good, length, delivery, outside, off, stump, jaques, lets, go, past, runs, fielded, boucher]   \n",
       "4  [steyn, jaques, fuller, length, outside, off, stump, jaques, drives, in, air, over, cover, fielder, 4, runs]         \n",
       "\n",
       "                                                                                                       lemmatized  \\\n",
       "0  [steyn, jaques, full, on, leg, swing, in, jaques, let, go, past, run, field, boucher]                            \n",
       "1  [steyn, jaques, good, length, down, leg, jaques, drive, run, field, botha]                                       \n",
       "2  [steyn, jaques, short, a, length, outside, off, stump, jaques, play, shoot, run, field, boucher]                 \n",
       "3  [ball, steyn, jaques, good, length, delivery, outside, off, stump, jaques, let, go, past, run, field, boucher]   \n",
       "4  [steyn, jaques, fuller, length, outside, off, stump, jaques, drive, in, air, over, cover, fielder, 4, run]       \n",
       "\n",
       "                                         sequence  \\\n",
       "0  [14, 3, 9, 54, 4, 124, 20, 68, 29, 89]           \n",
       "1  [16, 5, 17, 9, 22, 29, 89]                       \n",
       "2  [12, 1, 5, 7, 2, 10, 41, 431, 29, 89]            \n",
       "3  [6, 16, 5, 36, 7, 2, 10, 124, 20, 68, 29, 89]    \n",
       "4  [80, 5, 7, 2, 10, 22, 4, 165, 23, 15, 105, 29]   \n",
       "\n",
       "                                                     lemmatized_common  \\\n",
       "0  full on leg swing in let go past run field                            \n",
       "1  good length down leg drive run field                                  \n",
       "2  short a length outside off stump play shoot run field                 \n",
       "3  ball good length delivery outside off stump let go past run field     \n",
       "4  fuller length outside off stump drive in air over cover fielder run   \n",
       "\n",
       "     ...           90        91        92        93        94        95  \\\n",
       "0    ...    -0.208410  0.027172 -0.236194  0.126792 -0.473070  0.022373   \n",
       "1    ...    -0.361614 -0.087467 -0.298755 -0.052747 -0.529953 -0.011515   \n",
       "2    ...    -0.133592 -0.047485 -0.200691 -0.206948 -0.420979 -0.022429   \n",
       "3    ...    -0.198405  0.021079 -0.183381 -0.171802 -0.501083 -0.044090   \n",
       "4    ...    -0.009995 -0.100273 -0.312664 -0.169811 -0.413796  0.154531   \n",
       "\n",
       "         96        97        98        99  \n",
       "0  0.030191  0.081813  0.545245  0.132145  \n",
       "1  0.070159  0.023637  0.693554  0.168549  \n",
       "2 -0.015349  0.145458  0.567531  0.241330  \n",
       "3  0.078121  0.231797  0.435399  0.297424  \n",
       "4  0.028461  0.172708  0.572854  0.015922  \n",
       "\n",
       "[5 rows x 522 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.reset_index(drop=True, inplace=True)\n",
    "# ngramPresenceDf.reset_index(drop=True, inplace=True)\n",
    "df_train = pd.concat([df, ngramPresenceDf, vectors], axis=1)\n",
    "# ngfeatures = list(ngramsImportant.keys())\n",
    "# df_train[ngfeatures] = df_train[ngfeatures].div(df_train[ngfeatures].sum(axis=1), axis=0).fillna(0)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_features = list(ngramsImportant)\n",
    "X_features = [i for i in range(len(embeddings_dict['hello']))] + list(ngramsImportant)\n",
    "y_features = cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2611, 512)\n"
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "# X, X_test, y, y_test = train_test_split(df_train[X_features], df_train[y_features], stratify = df_train[y_features], test_size=0.15, random_state=seed)\n",
    "# X, X_test = X.values, X_test.values\n",
    "# y = y.values\n",
    "\n",
    "X, y = df_train[X_features].values, df_train[y_features].values\n",
    "# pca = PCA(n_components=50)\n",
    "# X = pca.fit_transform(X)\n",
    "# print(np.cumsum(pca.explained_variance_ratio_))\n",
    "print(X.shape)\n",
    "# print(f\"X shape: {X.shape}, X_test shape: {X_test.shape}\\ny shape: {y.shape}, y_test.shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Linear SVM\", \"RBF SVM\", \"Random Forest\", \"Neural Net\"]\n",
    "\n",
    "classifiers = [\n",
    "    SVC(kernel=\"linear\", C=0.05),\n",
    "    SVC(gamma='scale', C=1),\n",
    "    RandomForestClassifier(max_depth=20, n_estimators=50, max_features=14),\n",
    "    MLPClassifier(alpha=1.2, max_iter=2000, shuffle=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Linear SVM - 0.80!\n",
      "Done RBF SVM - 0.74!\n",
      "Done Random Forest - 0.69!\n",
      "Done Neural Net - 0.74!\n"
     ]
    }
   ],
   "source": [
    "scores = defaultdict(list)\n",
    "for name, clf in zip(names, classifiers):\n",
    "    for i, (train_fold, test_fold) in enumerate(skf.split(X,y)):\n",
    "        train_x, test_x = X[train_fold], X[test_fold]\n",
    "        train_y, test_y = y[train_fold], y[test_fold]\n",
    "        clf.fit(train_x, train_y)\n",
    "        acc = clf.score(test_x, test_y)\n",
    "        scores[name].append(acc)\n",
    "    print(f\"Done {name} - {acc:<.2f}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM           - 0.787\n",
      "Neural Net           - 0.777\n",
      "RBF SVM              - 0.734\n",
      "Random Forest        - 0.705\n"
     ]
    }
   ],
   "source": [
    "for name, s in sorted(scores.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{name:<20} - {np.array(s).mean():<.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19996663, 0.19685536, 0.19674006, 0.19967063, 0.20676732])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "weights = []\n",
    "for name, s in scores.items():\n",
    "    m = np.array(s).mean()\n",
    "    weights.append(m)\n",
    "weights = np.array(weights)\n",
    "weights = weights / weights.sum()\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 = 0.771!\n",
      "Fold 2 = 0.763!\n",
      "Fold 3 = 0.771!\n",
      "Fold 4 = 0.821!\n",
      "Fold 5 = 0.802!\n",
      "Fold 6 = 0.744!\n",
      "Fold 7 = 0.817!\n",
      "Fold 8 = 0.773!\n",
      "Fold 9 = 0.780!\n",
      "Fold 10 = 0.740!\n"
     ]
    }
   ],
   "source": [
    "names = [\"Linear SVM\", \"RBF SVM\", \"Decision Tree\", \"Random Forest\", \"Neural Net\"]\n",
    "\n",
    "classifiers_ensemble = [\n",
    "    SVC(kernel=\"linear\", C=0.05, probability=True),\n",
    "    SVC(gamma='scale', C=1, probability=True),\n",
    "    DecisionTreeClassifier(max_depth=20),\n",
    "    RandomForestClassifier(max_depth=20, n_estimators=20, max_features=15),\n",
    "    MLPClassifier(alpha=1.2, max_iter=2000)\n",
    "]\n",
    "\n",
    "scores_ensemble = []\n",
    "for i, (train_fold, test_fold) in enumerate(skf.split(X,y)):\n",
    "    train_x, test_x = X[train_fold], X[test_fold]\n",
    "    train_y, test_y = y[train_fold], y[test_fold]\n",
    "    \n",
    "    class_weights = class_weight.compute_class_weight('balanced', np.unique(train_y), np.ravel(train_y))\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "    clf = classifiers_ensemble[4]\n",
    "    clf.class_weight = class_weights\n",
    "    clf.fit(train_x, train_y)\n",
    "    clf_preds = clf.predict_proba(test_x)\n",
    "    clf_class_preds = clf_preds.argmax(axis=1)\n",
    "    \n",
    "    report = classification_report(test_y, clf_class_preds, output_dict=True)\n",
    "    conf_mat = confusion_matrix(clf_class_preds, test_y)\n",
    "    acc = np.sum(conf_mat.diagonal()) / np.sum(conf_mat)\n",
    "    scores_ensemble.append([report, acc])\n",
    "    print(f\"Fold {i+1} = {acc:.3f}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg acc: 0.778\n"
     ]
    }
   ],
   "source": [
    "print(f'Avg acc: {np.array([x[1] for x in scores_ensemble]).mean():>.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassPrecisions(scores):\n",
    "    classReport = {}\n",
    "    for lth in range(0, len(np.unique(train_y))):\n",
    "        classReport[lth] = {}\n",
    "        classReport[lth]['precision'] = 0\n",
    "        classReport[lth]['recall'] = 0\n",
    "        for report, acc in scores:\n",
    "            classReport[lth]['precision'] += report[str(lth)]['precision']\n",
    "            classReport[lth]['recall'] += report[str(lth)]['recall']\n",
    "        classReport[lth]['precision'] /= 10\n",
    "        classReport[lth]['recall'] /= 10\n",
    "    return classReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "straight          |  86% right, found  90% of the ones available\n",
      "outside off       |  82% right, found  82% of the ones available\n",
      "wide outside off  |  80% right, found  72% of the ones available\n",
      "down leg          |  77% right, found  54% of the ones available\n",
      "wide down leg     |   0% right, found   0% of the ones available\n"
     ]
    }
   ],
   "source": [
    "length_class_to_label = {\n",
    "    0: 'full toss',\n",
    "    1: 'yorker',\n",
    "    2: 'full',\n",
    "    3: 'good length',\n",
    "    4: 'back of a length',\n",
    "    5: 'short',\n",
    "}\n",
    "\n",
    "line_class_to_label = {\n",
    "    0: 'wide outside off',\n",
    "    1: 'outside off',\n",
    "    2: 'straight',\n",
    "    3: 'down leg',\n",
    "    4: 'wide down leg',\n",
    "}\n",
    "\n",
    "for cl, report in sorted(getClassPrecisions(scores_ensemble).items(), key=lambda x:x[1]['recall'], reverse=True):\n",
    "    print(f\"{line_class_to_label[int(cl)]:<17} | {report['precision']*100:>3.0f}% right, found {report['recall']*100:>3.0f}% of the ones available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(classifiers_ensemble, \"model_list_trained\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
